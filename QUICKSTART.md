# TDM ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” TDMì„ ë¹ ë¥´ê²Œ ì‹œì‘í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## 1. ì„¤ì¹˜ (5ë¶„)

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Anaconda ë˜ëŠ” Miniconda
- Python 3.9 ì´ìƒ
- PyTorch 2.0 ì´ìƒ
- Gymnasium

### ì„¤ì¹˜ ëª…ë ¹ì–´ (ì•„ë‚˜ì½˜ë‹¤ - ê¶Œì¥)

```bash
# 1. ì•„ë‚˜ì½˜ë‹¤ í™˜ê²½ ìƒì„±
conda env create -f environment.yml

# 2. í™˜ê²½ í™œì„±í™”
conda activate tdm

# 3. í™˜ê²½ í™•ì¸
python --version  # Python 3.9 ì´ìƒ í™•ì¸
```

### ì„¤ì¹˜ ëª…ë ¹ì–´ (pip ì‚¬ìš©)

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv

# 2. ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 4. MuJoCo í™˜ê²½ ì„¤ì¹˜ (ë¡œë´‡ í™˜ê²½ ì‚¬ìš© ì‹œ)
pip install gymnasium[mujoco]
```

## 2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (2ë¶„)

êµ¬í˜„ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤:

```bash
python test_tdm.py
```

ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ë©´ âœ“ í‘œì‹œê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.

## 3. ê°„ë‹¨í•œ í›ˆë ¨ (10ë¶„)

ê°€ì¥ ê°„ë‹¨í•œ ì˜ˆì œë¡œ TDMì„ í›ˆë ¨í•©ë‹ˆë‹¤:

```bash
# Reacher í™˜ê²½ì—ì„œ í›ˆë ¨ (ê°„ë‹¨í•œ ì‘ì—…)
# config.yamlì—ì„œ nameì„ "Reacher-v5"ë¡œ ì„¤ì •
python train.py
```

í›ˆë ¨ì´ ì‹œì‘ë˜ë©´:
- ì½˜ì†”ì— ì§„í–‰ ìƒí™©ì´ ì¶œë ¥ë©ë‹ˆë‹¤
- `./logs/` í´ë”ì— ë¡œê·¸ê°€ ì €ì¥ë©ë‹ˆë‹¤
- TensorBoardë¡œ ì‹œê°í™” ê°€ëŠ¥í•©ë‹ˆë‹¤

### TensorBoardë¡œ ëª¨ë‹ˆí„°ë§

ìƒˆ í„°ë¯¸ë„ì—ì„œ:

```bash
tensorboard --logdir=./logs
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:6006` ì ‘ì†

## 4. í›ˆë ¨ëœ ëª¨ë¸ í‰ê°€ (3ë¶„)

í›ˆë ¨ì´ ì™„ë£Œë˜ë©´ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤:

```bash
# ê¸°ë³¸ í‰ê°€
python evaluate.py --model ./logs/Reacher-v5_*/model_final.pt

# ì‹œê°í™”ì™€ í•¨ê»˜ í‰ê°€
python evaluate.py --model ./logs/Reacher-v5_*/model_final.pt --render

# ê¶¤ì  ì‹œê°í™”
python evaluate.py --model ./logs/Reacher-v5_*/model_final.pt --visualize
```

## 5. ë‹¤ë¥¸ í™˜ê²½ìœ¼ë¡œ ë³€ê²½

### Pusher í™˜ê²½

`config.yaml` íŒŒì¼ì„ ì—´ê³ :

```yaml
env:
  name: "Pusher-v5"
  max_episode_steps: 50
```

ê·¸ ë‹¤ìŒ í›ˆë ¨:

```bash
python train.py
```

### HalfCheetah í™˜ê²½

```yaml
env:
  name: "HalfCheetah-v5"
  max_episode_steps: 99
```

### Ant í™˜ê²½

```yaml
env:
  name: "Ant-v5"
  max_episode_steps: 50

task:
  locomotion_task_type: "position"  # ë˜ëŠ” "position_velocity"
```

## 6. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë ¤ë©´ `config.yaml`ì—ì„œ ì¡°ì •:

### ë¹ ë¥¸ í•™ìŠµ (ë‚®ì€ ì„±ëŠ¥)

```yaml
tdm:
  tau_max: 10  # ì‘ì€ ê°’

training:
  updates_per_step: 5  # ì ì€ ì—…ë°ì´íŠ¸
  total_timesteps: 100000  # ì§§ì€ í›ˆë ¨
```

### ë†’ì€ ì„±ëŠ¥ (ëŠë¦° í•™ìŠµ)

```yaml
tdm:
  tau_max: 25  # í° ê°’

training:
  updates_per_step: 20  # ë§ì€ ì—…ë°ì´íŠ¸
  total_timesteps: 5000000  # ê¸´ í›ˆë ¨
```

## 7. ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°ì±…**: `config.yaml`ì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°

```yaml
training:
  batch_size: 64  # 128ì—ì„œ 64ë¡œ
```

### ë¬¸ì œ: í•™ìŠµì´ ë„ˆë¬´ ëŠë¦¼

**í•´ê²°ì±…**: ì—…ë°ì´íŠ¸ ë¹ˆë„ ì¤„ì´ê¸°

```yaml
training:
  updates_per_step: 1  # 10ì—ì„œ 1ë¡œ
```

### ë¬¸ì œ: ì„±ëŠ¥ì´ ë‚®ìŒ

**í•´ê²°ì±…**:
1. ë” ì˜¤ë˜ í›ˆë ¨ (`total_timesteps` ì¦ê°€)
2. `tau_max` ì¡°ì • (15-25 ì‹œë„)
3. `reward_scale` ì¡°ì • (0.1-10 ì‹œë„)

### ë¬¸ì œ: í™˜ê²½ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

**í•´ê²°ì±…**: Gymnasium í™˜ê²½ ì„¤ì¹˜

```bash
# ì•„ë‚˜ì½˜ë‹¤ í™˜ê²½ì—ì„œ
conda install -c conda-forge mujoco

# ë˜ëŠ” pipë¡œ
pip install gymnasium[mujoco]
```

### ë¬¸ì œ: ì•„ë‚˜ì½˜ë‹¤ í™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…**: í™˜ê²½ í™œì„±í™” í™•ì¸

```bash
# í™˜ê²½ í™œì„±í™”
conda activate tdm

# í™˜ê²½ ëª©ë¡ í™•ì¸
conda env list

# í™˜ê²½ ì‚­ì œ í›„ ì¬ìƒì„± (í•„ìš”ì‹œ)
conda env remove -n tdm
conda env create -f environment.yml
```

## 8. ì˜ˆì œ ì½”ë“œ

### Python ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©

```python
import yaml
import torch
from tdm import TDM
from env_wrapper import TDMEnvWrapper
from mpc_planner import TaskSpecificPlanner

# ì„¤ì • ë¡œë“œ
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# í™˜ê²½ ìƒì„±
import gymnasium as gym
env = gym.make('Reacher-v5')
env = TDMEnvWrapper(env, 'end_effector', config['task'])

# TDM ìƒì„±
state_dim = env.observation_space.shape[0]
action_dim = env.action_space.shape[0]
goal_dim = env.goal_dim
action_range = (env.action_space.low, env.action_space.high)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
tdm = TDM(state_dim, action_dim, goal_dim, action_range, config, device)

# í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
tdm.load('./logs/Reacher-v5_*/model_final.pt')

# Planner ìƒì„±
planner = TaskSpecificPlanner(tdm, config, 'Reacher-v5', 'end_effector')

# ì‹¤í–‰
obs, info = env.reset()
goal = env.get_goal()

for step in range(100):
    action = planner.select_action(obs, goal, tau=25)
    obs, reward, done, info = env.step(action)
    
    if done:
        break

env.close()
```

## 9. ë‹¤ìŒ ë‹¨ê³„

### ë” ë°°ìš°ê¸°

1. **README.md** - ì „ì²´ ë¬¸ì„œ
2. **example_usage.py** - ë‹¤ì–‘í•œ ì˜ˆì œ
3. **utils.py** - ë¶„ì„ ë„êµ¬

### ê³ ê¸‰ ê¸°ëŠ¥

1. **Goal Relabeling ë¶„ì„**: `utils.py`ì˜ `analyze_goal_relabeling_impact()`
2. **Horizon ë¹„êµ**: `utils.py`ì˜ `compare_horizons()`
3. **í›ˆë ¨ ê³¡ì„  ì‹œê°í™”**: `utils.py`ì˜ `plot_training_curves()`

### ë…¼ë¬¸ ì¬í˜„

ë…¼ë¬¸ì˜ ì‹¤í—˜ì„ ì¬í˜„í•˜ë ¤ë©´:

1. ê° í™˜ê²½ì— ëŒ€í•´ ë³„ë„ë¡œ í›ˆë ¨
2. ì—¬ëŸ¬ random seedë¡œ ì‹¤í–‰ (seed ë³€ê²½)
3. TensorBoardë¡œ ê²°ê³¼ ë¹„êµ
4. `utils.py`ì˜ ë„êµ¬ë¡œ ë¶„ì„

## 10. ë¹ ë¥¸ ì°¸ì¡°

### ì£¼ìš” ëª…ë ¹ì–´

```bash
# í›ˆë ¨
python train.py

# í‰ê°€
python evaluate.py --model <model_path>

# í…ŒìŠ¤íŠ¸
python test_tdm.py

# ì˜ˆì œ ì‹¤í–‰
python example_usage.py
```

### ì£¼ìš” íŒŒì¼

- `config.yaml` - ì„¤ì •
- `train.py` - í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
- `evaluate.py` - í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
- `tdm.py` - TDM ì•Œê³ ë¦¬ì¦˜
- `networks.py` - ì‹ ê²½ë§ êµ¬ì¡°
- `mpc_planner.py` - MPC ê³„íš

### ì£¼ìš” ë””ë ‰í† ë¦¬

- `./logs/` - í›ˆë ¨ ë¡œê·¸ ë° ëª¨ë¸
- `./logs/*/` - í™˜ê²½ë³„ ë¡œê·¸

## ë„ì›€ë§

ë¬¸ì œê°€ ìˆìœ¼ë©´:
1. `test_tdm.py` ì‹¤í–‰í•˜ì—¬ ë¬¸ì œ í™•ì¸
2. TensorBoard ë¡œê·¸ í™•ì¸
3. `config.yaml` ì„¤ì • ê²€í† 
4. GitHub Issuesì— ë¬¸ì œ ë³´ê³ 

í–‰ìš´ì„ ë¹•ë‹ˆë‹¤! ğŸš€

